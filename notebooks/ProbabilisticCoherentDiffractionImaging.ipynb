{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNhOOvBg0juu17GngMoasXS"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, TensorDataset, DataLoader, random_split\n",
        "\n",
        "from skimage.transform import resize\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "z0l7gefLoyRw"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "from google.colab import files\n",
        "\n",
        "drive.mount(\"/content/gdrive\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WlAVGUAIbp2t",
        "outputId": "e5a33c7c-9a60-4c84-f975-bd8665fabca1"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile models.py\n",
        "\"\"\"\n",
        "Classes for models to be trained.\n",
        "\"\"\"\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "\n",
        "def contraction_block(in_channels: int,\n",
        "                      mid_channels: int,\n",
        "                      out_channels: int,\n",
        "                      kernel_size: int=3,\n",
        "                      stride: int=1,\n",
        "                      padding: int=1,\n",
        "                      pool_factor:int=2) -> nn.Module:\n",
        "  \"\"\"\n",
        "  Creates a constituent Conv block for the encoder section of the ptychoNN model.\n",
        "  Consists of Conv-Relu-Conv-Relu-Maxpool layers.\n",
        "  Args:\n",
        "    in_channels: Input channels to the block\n",
        "    mid_channels: intermediate channels (ie, output of first conv layer and input channels to the second)\n",
        "    out_channels: Final number of output channels from the conv block\n",
        "    kernel_size: Uniform kernel size across both conv layers in the block\n",
        "    stride: Uniform stride across both conv layers in the block\n",
        "    padding: Uniform padding across both conv layers in the block\n",
        "    pool_factor: Kernel size of the square max pool\n",
        "  Returns:\n",
        "    nn.Sequential container of modules.\n",
        "  \"\"\"\n",
        "  return nn.Sequential(\n",
        "      nn.Conv2d(in_channels=in_channels, out_channels=mid_channels, kernel_size=kernel_size, stride=stride, padding=padding),\n",
        "      nn.ReLU(),\n",
        "      nn.Conv2d(in_channels=mid_channels, out_channels=out_channels, kernel_size=kernel_size, stride=stride, padding=padding),\n",
        "      nn.ReLU(),\n",
        "      nn.MaxPool2d(pool_factor)\n",
        "  )\n",
        "\n",
        "\n",
        "def expansion_block(in_channels: int,\n",
        "                    mid_channels: int,\n",
        "                    out_channels: int,\n",
        "                    kernel_size: int=3,\n",
        "                    stride: int=1,\n",
        "                    padding: int=1,\n",
        "                    upsamling_factor:int=2) -> nn.Module:\n",
        "    \"\"\"\n",
        "  Creates a constituent Conv block for the decoder sections of the ptychoNN model.\n",
        "  Consists of Conv-Relu-Conv-Relu-Upsample layers.\n",
        "  Args:\n",
        "    in_channels: Input channels to the block\n",
        "    mid_channels: intermediate channels (ie, output of first conv layer and input channels to the second)\n",
        "    out_channels: Final number of output channels from the conv block\n",
        "    kernel_size: Uniform kernel size across both conv layers in the block\n",
        "    stride: Uniform stride across both conv layers in the block\n",
        "    padding: Uniform padding across both conv layers in the block\n",
        "    upsampling_factor: Scale factor for the upsampling layer\n",
        "  Returns:\n",
        "    nn.Sequential container of modules.\n",
        "  \"\"\"\n",
        "    return nn.Sequential(\n",
        "      nn.Conv2d(in_channels=in_channels, out_channels=mid_channels, kernel_size=kernel_size, stride=stride, padding=padding),\n",
        "      nn.ReLU(),\n",
        "      nn.Conv2d(in_channels=mid_channels, out_channels=out_channels, kernel_size=kernel_size, stride=stride, padding=padding),\n",
        "      nn.ReLU(),\n",
        "      nn.Upsample(scale_factor=upsamling_factor, mode='bilinear')\n",
        "      )\n",
        "\n",
        "\n",
        "class PtychoNNBase(nn.Module):\n",
        "  \"\"\"\n",
        "  Defines the deterministic version of the PtychoNN model\n",
        "  Attributes:\n",
        "    nconv: number of feature maps from the first conv layer.\n",
        "  \"\"\"\n",
        "  def __init__(self, nconv: int=32, **kwargs):\n",
        "    super().__init__(**kwargs)\n",
        "    self.encoder = nn.Sequential(\n",
        "        contraction_block(in_channels=1, mid_channels=nconv, out_channels=nconv),\n",
        "        contraction_block(in_channels=nconv, mid_channels=2*nconv, out_channels=2*nconv),\n",
        "        contraction_block(in_channels=2*nconv, mid_channels=4*nconv, out_channels=4*nconv)\n",
        "    )\n",
        "    self.amplitude_decoder = nn.Sequential(\n",
        "        expansion_block(in_channels=4*nconv, mid_channels=4*nconv, out_channels=4*nconv),\n",
        "        expansion_block(in_channels=4*nconv, mid_channels=2*nconv, out_channels=2*nconv),\n",
        "        expansion_block(in_channels=2*nconv, mid_channels=2*nconv, out_channels=2*nconv),\n",
        "        nn.Conv2d(in_channels=2*nconv, out_channels=1, kernel_size=3, stride=1, padding=1),\n",
        "        nn.Sigmoid()\n",
        "    )\n",
        "    self.phase_decoder = nn.Sequential(\n",
        "        expansion_block(in_channels=4*nconv, mid_channels=4*nconv, out_channels=4*nconv),\n",
        "        expansion_block(in_channels=4*nconv, mid_channels=2*nconv, out_channels=2*nconv),\n",
        "        expansion_block(in_channels=2*nconv, mid_channels=2*nconv, out_channels=2*nconv),\n",
        "        nn.Conv2d(in_channels=2*nconv, out_channels=1, kernel_size=3, stride=1, padding=1),\n",
        "        nn.Tanh()\n",
        "    )\n",
        "\n",
        "  def forward(self, x):\n",
        "    encoded = self.encoder(x)\n",
        "    amps = self.amplitude_decoder(encoded)\n",
        "    phis = self.phase_decoder(encoded)\n",
        "    phis = phis * np.pi\n",
        "    return amps, phis"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CfAsTlX-5RNk",
        "outputId": "fc1779a3-5fe4-4e1e-ca25-ebc7a51e8c75"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing models.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# H, W = 64, 64\n",
        "# NLINES = 100\n",
        "# NLTEST = 60\n",
        "# N_VALID = 805"
      ],
      "metadata": {
        "id": "HluNpILJRXze"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile data_setup.py\n",
        "\"\"\"\n",
        "Classes & Functions to download data, create datasets and dataloaders.\n",
        "\"\"\"\n",
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import Dataset, TensorDataset, DataLoader, random_split\n",
        "\n",
        "from skimage.transform import resize\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "def process_data(diffraction_data: str, real_data: str, NLINES: int, H: int, W: int) -> tuple:\n",
        "  \"\"\"\n",
        "  Takes links for the diffraction and real data files, processes them and\n",
        "  returns numpy arrays for diffraction data (input) and outputs of real-space\n",
        "  amplitude and phase.\n",
        "  Args:\n",
        "    diffraction_data: path to diffraction data file\n",
        "    real_data: path to real space data file\n",
        "    NLINES: Number of lines of scanned data to use for train set\n",
        "    H: Height of images\n",
        "    W: Width of images\n",
        "  Returns:\n",
        "    tuple of (X_train, Y_I_train, Y_phi_train, X_test, Y_I_test, Y_phi_test)\n",
        "  \"\"\"\n",
        "  data_diffr = np.load(diffraction_data)['arr_0']\n",
        "  real_space = np.load(real_data)\n",
        "  amp, ph = np.abs(real_space), np.angle(real_space)\n",
        "\n",
        "  data_diffr_red = np.zeros((data_diffr.shape[0], data_diffr.shape[1], 64, 64), float)\n",
        "  for i in range(data_diffr.shape[0]):\n",
        "    for j in range(data_diffr.shape[1]):\n",
        "      data_diffr_red[i,j] = resize(data_diffr[i,j,32:-32,32:-32],(64,64),preserve_range=True, anti_aliasing=True)\n",
        "      data_diffr_red[i,j] = np.where(data_diffr_red[i,j]<3,0,data_diffr_red[i,j])\n",
        "\n",
        "  tst_strt = amp.shape[0]-NLTEST #Where to index from\n",
        "  X_train = data_diffr_red[:NLINES,:].reshape(-1,H,W)[:,np.newaxis,:,:]\n",
        "  X_test = data_diffr_red[tst_strt:,tst_strt:].reshape(-1,H,W)[:,np.newaxis,:,:]\n",
        "  Y_I_train = amp[:NLINES,:].reshape(-1,H,W)[:,np.newaxis,:,:]\n",
        "  Y_I_test = amp[tst_strt:,tst_strt:].reshape(-1,H,W)[:,np.newaxis,:,:]\n",
        "  Y_phi_train = ph[:NLINES,:].reshape(-1,H,W)[:,np.newaxis,:,:]\n",
        "  Y_phi_test = ph[tst_strt:,tst_strt:].reshape(-1,H,W)[:,np.newaxis,:,:]\n",
        "\n",
        "  X_train, Y_I_train, Y_phi_train = shuffle(X_train, Y_I_train, Y_phi_train, random_state=0)\n",
        "  return X_train, Y_I_train, Y_phi_train, X_test, Y_I_test, Y_phi_test\n",
        "\n",
        "\n",
        "def get_dataloaders(data_path, val_num: int=805, batch_size: int=64, num_workers: int=2)->dict:\n",
        "  \"\"\"\n",
        "  Generates train, validation and test dataloaders from the raw numpy files.\n",
        "  Args:\n",
        "    data_path: Location of raw numpy files\n",
        "    val_num: Number of lines of scan to be saved as validation data\n",
        "    batch_size: uniform batch size\n",
        "    num_workers: number of data loader worker processes\n",
        "  Returns:\n",
        "    Dict of {\"train_dl\": train_dl, \"val_dl\": val_dl, \"test_dl\": test_dl}\n",
        "  \"\"\"\n",
        "  X_train, Y_I_train, Y_phi_train = torch.from_numpy(np.load(data_path+\"X_train.npy\")).to(torch.float), torch.from_numpy(np.load(data_path+\"Y_I_train.npy\")), torch.from_numpy(np.load(data_path+\"Y_phi_train.npy\"))\n",
        "  X_test, Y_I_test, Y_phi_test = torch.from_numpy(np.load(data_path+\"X_test.npy\")).to(torch.float), torch.from_numpy(np.load(data_path+\"Y_I_test.npy\")), torch.from_numpy(np.load(data_path+\"Y_phi_test.npy\"))\n",
        "  train_data_init = TensorDataset(X_train, Y_I_train, Y_phi_train)\n",
        "  test_dataset = TensorDataset(X_test, Y_I_test, Y_phi_test)\n",
        "  train_dataset, val_dataset = random_split(train_data_init, [X_train.shape[0]-val_num, val_num])\n",
        "\n",
        "  train_dl = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=num_workers)\n",
        "  val_dl = DataLoader(val_dataset, batch_size=batch_size, shuffle=True, num_workers=num_workers)\n",
        "  test_dl = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=num_workers)\n",
        "\n",
        "  return {\"train_dl\": train_dl, \"val_dl\": val_dl, \"test_dl\": test_dl}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3NeIsnXfBxH7",
        "outputId": "0e4d6c0f-31de-4ada-92a8-103b94f1170d"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing data_setup.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile utils.py\n",
        "\"\"\"\n",
        "Utility functions for model training and evaluation.\n",
        "\"\"\"\n",
        "import torch\n",
        "import os\n",
        "\n",
        "\n",
        "def get_devices() -> torch.device:\n",
        "  \"\"\"\n",
        "  Returns gpu device if available, else cpu\n",
        "  \"\"\"\n",
        "  return torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
        "\n",
        "\n",
        "def set_seeds(seed: int = 42):\n",
        "  \"\"\"\n",
        "  Sets torch seeds to ensure reproducability.\n",
        "  \"\"\"\n",
        "  torch.manual_seed(seed)\n",
        "  torch.cuda.manual_seed(seed)\n",
        "  os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
        "\n",
        "\n",
        "def save_model(model_dir: str, model_name: str, model: torch.nn.Module):\n",
        "  \"\"\"\n",
        "  Saves pytorch model in model_dir with model_name.\n",
        "  Args:\n",
        "    model_dir: Directory to save model in.\n",
        "    model_name: name of file to store model.\n",
        "    model: model to be saved.\n",
        "  Returns:\n",
        "    None\n",
        "  \"\"\"\n",
        "  os.makedirs(model_dir, exist_ok=True)\n",
        "  if not model_name.endswith(\"pt\"):\n",
        "    model_name += \".pt\"\n",
        "  torch.save(model.state_dict(), os.path.join(model_dir, model_name))\n",
        "\n",
        "\n",
        "def create_summary_writer(experiment_name: str, model_name: str, extras: str = None):\n",
        "        # -> torch.utils.tensorboard.SummaryWriter:\n",
        "  \"\"\"\n",
        "  Instantiates and returns a Summary writer for the experiment, that writers to\n",
        "  runs/experiment_name/model_name/extras\n",
        "  Args:\n",
        "    experiment_name: Name of experiment (say, dataset)\n",
        "    model_name: Name of model used\n",
        "    extras: Additional details\n",
        "  Returns:\n",
        "    SummaryWriter instance for the experiment\n",
        "  \"\"\"\n",
        "  if extras:\n",
        "    log_dir = os.path.join(\"runs/\", experiment_name, model_name, extras)\n",
        "  else:\n",
        "    log_dir = os.path.join(\"runs/\", experiment_name, model_name)\n",
        "  writer = torch.utils.tensorboard.SummaryWriter(log_dir)\n",
        "  return writer"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3D0vEOhkPU8g",
        "outputId": "88aca613-439a-4ef6-f8a8-284285238bf4"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing utils.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile engine.py\n",
        "\"\"\"\n",
        "Functions to train and evaluate model on the image dataset\n",
        "\"\"\"\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "\n",
        "def train_step(model: torch.nn.Module,\n",
        "               train_dl: torch.utils.data.DataLoader,\n",
        "               loss_fn: torch.nn.Module,\n",
        "               opt: torch.optim.Optimizer,\n",
        "               device: torch.device\n",
        "               ) -> dict:\n",
        "  \"\"\"\n",
        "  Performs 1 epoch of training of model on train dataloader,\n",
        "  returning model loss on the amplitude and phase reconstruction.\n",
        "  Args:\n",
        "    model: model too be trained\n",
        "    train_dl: Dataloader with training data\n",
        "    loss_fn: Differentiable loss function to be used for gradients\n",
        "    opt: Optimizer to train model.\n",
        "    device: Device on which model and data will reside.\n",
        "  Returns:\n",
        "      Dict with keys \"total_loss\", \"amp_loss\" and \"phase_loss\".\n",
        "  \"\"\"\n",
        "  model.train()\n",
        "  total_loss, amplitude_loss, phase_loss = 0.0, 0.0, 0.0\n",
        "  for ft_images, amps, phis in train_dl:\n",
        "    ft_images, amps, phis = ft_images.to(device), amps.to(device), phis.to(device)\n",
        "    pred_amps, pred_phis = model(ft_images)\n",
        "    amp_loss = loss_fn(pred_amps, amps)\n",
        "    phi_loss = loss_fn(pred_phis, phis)\n",
        "    loss = amp_loss + phi_loss\n",
        "    opt.zero_grad()\n",
        "    loss.backward()\n",
        "    opt.step()\n",
        "\n",
        "    total_loss += loss.detach().item()\n",
        "    amplitude_loss += amp_loss.detach().item()\n",
        "    phase_loss += phi_loss.detach().item()\n",
        "\n",
        "  model.eval()\n",
        "  return {\"total_loss\": total_loss/len(train_dl),\n",
        "          \"amp_loss\": amplitude_loss/len(train_dl),\n",
        "          \"phase_loss\": phase_loss/len(train_dl)}\n",
        "\n",
        "\n",
        "def val_step(model: torch.nn.Module,\n",
        "            val_dl: torch.utils.data.DataLoader,\n",
        "            loss_fn: torch.nn.Module,\n",
        "            device: torch.device\n",
        "            ) -> dict:\n",
        "  \"\"\"\n",
        "  Performs 1 epoch of evaluation of model on validation dataloader,\n",
        "  returning model loss on the amplitude and phase reconstruction.\n",
        "  Args:\n",
        "    model: model too be trained\n",
        "    train_dl: Dataloader with training data\n",
        "    loss_fn: Loss function to be used for gradients\n",
        "    device: Device on which model and data will reside.\n",
        "  Returns:\n",
        "      Dict with keys \"total_loss\", \"amp_loss\" and \"phase_loss\".\n",
        "  \"\"\"\n",
        "  model.eval()\n",
        "  total_loss, amplitude_loss, phase_loss = 0.0, 0.0, 0.0\n",
        "  with torch.inference_mode():\n",
        "    for ft_images, amps, phis in val_dl:\n",
        "      ft_images, amps, phis = ft_images.to(device), amps.to(device), phis.to(device)\n",
        "      pred_amps, pred_phis = model(ft_images)\n",
        "      amp_loss = loss_fn(pred_amps, amps)\n",
        "      phi_loss = loss_fn(pred_phis, phis)\n",
        "      loss = amp_loss + phi_loss\n",
        "\n",
        "      total_loss += loss.detach().item()\n",
        "      amplitude_loss += amp_loss.detach().item()\n",
        "      phase_loss += phi_loss.detach().item()\n",
        "\n",
        "  return {\"total_loss\": total_loss/len(val_dl),\n",
        "          \"amp_loss\": amplitude_loss/len(val_dl),\n",
        "          \"phase_loss\": phase_loss/len(val_dl)}\n",
        "\n",
        "\n",
        "def train(model: torch.nn.Module,\n",
        "          train_dl: torch.utils.data.DataLoader,\n",
        "          val_dl: torch.utils.data.DataLoader,\n",
        "          loss_fn: torch.nn.Module,\n",
        "          opt: torch.optim.Optimizer,\n",
        "          device: torch.device,\n",
        "          num_epochs: int) -> dict:\n",
        "  \"\"\"\n",
        "  Performs defined number of epochs of training and evaluation for the model on\n",
        "  the data loaders, returning the loss history on amplitude and phase reconstruction.\n",
        "  Args:\n",
        "    model: model to be trained and evaluated.\n",
        "    train_dl: Dataloader with training data.\n",
        "    val_dl: Dataloader with testing data.\n",
        "    loss_fn: Differentiable loss function to use for gradients.\n",
        "    opt: Optimizer to tune model params.\n",
        "    device: Device on which model and eventually data shall reside\n",
        "    num_epochs: Number of epochs of training\n",
        "  Returns:\n",
        "    Dict with history of \"total_loss\", \"amp_loss\" and \"phase_loss\".\n",
        "  \"\"\"\n",
        "  amp_loss_train, phi_loss_train, amp_loss_val, phi_loss_val = [], [], [], []\n",
        "  for epoch in range(num_epochs):\n",
        "    train_results = train_step(model, train_dl, loss_fn, opt, device)\n",
        "    val_results = val_step(model, val_dl, loss_fn, device)\n",
        "    amp_loss_train.append(train_results[\"amp_loss\"])\n",
        "    phi_loss_train.append(train_results[\"phase_loss\"])\n",
        "    amp_loss_val.append(val_results[\"amp_loss\"])\n",
        "    phi_loss_val.append(val_results[\"phase_loss\"])\n",
        "    print(f\"Epoch: {epoch+1} Train Amp: {amp_loss_train[-1]} Train Phi: {phi_loss_train[-1]} Val Amp: {amp_loss_val[-1]} Val Phi: {phi_loss_val[-1]}\")\n",
        "\n",
        "  return {\"amp_loss_train\": amp_loss_train, \"phi_loss_train\": phi_loss_train,\n",
        "          \"amp_loss_val\": amp_loss_val, \"phi_loss_val\": phi_loss_val}\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YOwUkrB-qzfx",
        "outputId": "112a7d9e-2012-4fc1-b660-0f42470dd041"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting engine.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile train.py\n",
        "\"\"\"\n",
        "Takes parameters from user; trains, evaluates and saves models on\n",
        "Coherent Diffraction Imaging Data.\n",
        "\"\"\"\n",
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import os\n",
        "import argparse\n",
        "from data_setup import get_dataloaders\n",
        "from models import PtychoNNBase\n",
        "from engine import train\n",
        "from utils import get_devices, set_seeds, save_model\n",
        "\n",
        "\n",
        "parser = argparse.ArgumentParser()\n",
        "parser.add_argument(\"--data_path\", type=str, default=\"./gdrive/MyDrive/PtychoNNData/\")\n",
        "parser.add_argument(\"--num_epochs\", type=int, default=50)\n",
        "parser.add_argument(\"--lr\", type=float, default=0.001)\n",
        "parser.add_argument(\"--batch_size\", type=int, default=64)\n",
        "parser.add_argument(\"--model\", type=str, default=\"PtychoNNBase\")\n",
        "args = parser.parse_args()\n",
        "\n",
        "set_seeds(42)\n",
        "device = get_devices()\n",
        "d = get_dataloaders(args.data_path)\n",
        "train_dl, val_dl, test_dl = d[\"train_dl\"], d[\"val_dl\"], d[\"test_dl\"]\n",
        "model = PtychoNNBase().to(device)\n",
        "loss_fn = torch.nn.L1Loss()\n",
        "opt = torch.optim.Adam(model.parameters(), lr=args.lr)\n",
        "results = train(model, train_dl, val_dl, loss_fn, opt, device, args.num_epochs)\n",
        "model_name = args.model + str(args.num_epochs)\n",
        "save_model(\"./Models\", \"model_\" + args.model, model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WTJ7HT_D9_ow",
        "outputId": "c8150887-96c3-4864-dcbf-d089d113e702"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting train.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python train.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D9UA2HV56Apc",
        "outputId": "7c28ace4-17da-4e7a-c0e8-bf18c0a3eee0"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1 Train Amp: 0.020238792176931225 Train Phi: 0.6567434695974055 Val Amp: 0.008215938050013322 Val Phi: 0.5158808896174798\n",
            "Epoch: 2 Train Amp: 0.007671724149575418 Train Phi: 0.4740255963852216 Val Amp: 0.008045231457799673 Val Phi: 0.4405887172772334\n",
            "Epoch: 3 Train Amp: 0.006972887352592152 Train Phi: 0.4122034431002629 Val Amp: 0.006812496003336632 Val Phi: 0.38779001511060274\n",
            "Epoch: 4 Train Amp: 0.006723234862494419 Train Phi: 0.3710388399068282 Val Amp: 0.0069523019572863215 Val Phi: 0.35297871552980864\n",
            "Epoch: 5 Train Amp: 0.0065932906599068496 Train Phi: 0.34336983621369843 Val Amp: 0.006409328359250839 Val Phi: 0.34188271715090823\n",
            "Epoch: 6 Train Amp: 0.006467542519488968 Train Phi: 0.32303640882340434 Val Amp: 0.006432438412537942 Val Phi: 0.31913650265106785\n",
            "Epoch: 7 Train Amp: 0.00636363655492414 Train Phi: 0.30075326287596793 Val Amp: 0.006174770900263236 Val Phi: 0.29967005665485674\n",
            "Epoch: 8 Train Amp: 0.006295286765844253 Train Phi: 0.2820869913659834 Val Amp: 0.006200353041864359 Val Phi: 0.2924026067440326\n",
            "Epoch: 9 Train Amp: 0.006218376360973928 Train Phi: 0.2678328589789538 Val Amp: 0.006469209821751485 Val Phi: 0.2775457570186028\n",
            "Epoch: 10 Train Amp: 0.006127731323195426 Train Phi: 0.2569326349382121 Val Amp: 0.006129827816039324 Val Phi: 0.2653571413113521\n",
            "Epoch: 11 Train Amp: 0.006024996600031978 Train Phi: 0.24362875240617218 Val Amp: 0.006253753072367265 Val Phi: 0.25929014499370867\n",
            "Epoch: 12 Train Amp: 0.005963473590519513 Train Phi: 0.2325242388697349 Val Amp: 0.0058985974353093365 Val Phi: 0.25083786019912135\n",
            "Epoch: 13 Train Amp: 0.005883184783784166 Train Phi: 0.22286596545115675 Val Amp: 0.006133450087732994 Val Phi: 0.2495022461964534\n",
            "Epoch: 14 Train Amp: 0.00582653967367493 Train Phi: 0.21513889892081337 Val Amp: 0.005785596162940447 Val Phi: 0.24078534428889936\n",
            "Epoch: 15 Train Amp: 0.005731575656682253 Train Phi: 0.20654026814833845 Val Amp: 0.005850150034977839 Val Phi: 0.2294215697508592\n",
            "Epoch: 16 Train Amp: 0.00568200365316793 Train Phi: 0.20118114009312507 Val Amp: 0.0058107706359945815 Val Phi: 0.23026806230728442\n",
            "Epoch: 17 Train Amp: 0.00561492111939142 Train Phi: 0.1958473758717461 Val Amp: 0.00574872768125855 Val Phi: 0.22104493127419397\n",
            "Epoch: 18 Train Amp: 0.005554554845638979 Train Phi: 0.1897232953973395 Val Amp: 0.005735122133046389 Val Phi: 0.22543807900868928\n",
            "Epoch: 19 Train Amp: 0.005498689472690911 Train Phi: 0.18587461999270707 Val Amp: 0.0056693927886394355 Val Phi: 0.21484832351024336\n",
            "Epoch: 20 Train Amp: 0.005455425396857776 Train Phi: 0.18177468045984851 Val Amp: 0.005536707440534463 Val Phi: 0.2115577757358551\n",
            "Epoch: 21 Train Amp: 0.005405911193794286 Train Phi: 0.178715496320106 Val Amp: 0.005808663554489613 Val Phi: 0.21080052164884713\n",
            "Epoch: 22 Train Amp: 0.005350156437808251 Train Phi: 0.17339881687234138 Val Amp: 0.005587904355846918 Val Phi: 0.20431972810855278\n",
            "Epoch: 23 Train Amp: 0.005330065736804297 Train Phi: 0.1694354292737889 Val Amp: 0.005429550253141385 Val Phi: 0.19753494056371543\n",
            "Epoch: 24 Train Amp: 0.005250321582318225 Train Phi: 0.1683469844288407 Val Amp: 0.0054511931151724775 Val Phi: 0.19745440207994902\n",
            "Epoch: 25 Train Amp: 0.005210838140335293 Train Phi: 0.1640153063391043 Val Amp: 0.0053618893815347785 Val Phi: 0.20141103061345908\n",
            "Epoch: 26 Train Amp: 0.00517355557336281 Train Phi: 0.1614071132623002 Val Amp: 0.0054185541275029 Val Phi: 0.19362895649213058\n",
            "Epoch: 27 Train Amp: 0.005152650058628002 Train Phi: 0.15986038962667456 Val Amp: 0.00532072911468836 Val Phi: 0.19328660460618827\n",
            "Epoch: 28 Train Amp: 0.005116323457259264 Train Phi: 0.15658389674070988 Val Amp: 0.00541006472821419 Val Phi: 0.19230200464908892\n",
            "Epoch: 29 Train Amp: 0.00507203422517956 Train Phi: 0.15573803675224593 Val Amp: 0.005494933575391769 Val Phi: 0.18696618767885062\n",
            "Epoch: 30 Train Amp: 0.005037159705729414 Train Phi: 0.15241577853468172 Val Amp: 0.005376528196323376 Val Phi: 0.19177678456673256\n",
            "Epoch: 31 Train Amp: 0.005007359224554759 Train Phi: 0.1515641844048161 Val Amp: 0.0053837006696714805 Val Phi: 0.19326845040688148\n",
            "Epoch: 32 Train Amp: 0.00497289529950923 Train Phi: 0.14772532973828176 Val Amp: 0.005548058507534174 Val Phi: 0.18395104316564706\n",
            "Epoch: 33 Train Amp: 0.00494626034479822 Train Phi: 0.1463332022209048 Val Amp: 0.00547825709845011 Val Phi: 0.18260803818702698\n",
            "Epoch: 34 Train Amp: 0.004921855514081951 Train Phi: 0.14592582037259344 Val Amp: 0.005176080892292352 Val Phi: 0.18115167319774628\n",
            "Epoch: 35 Train Amp: 0.00492661045747322 Train Phi: 0.14421512498267025 Val Amp: 0.005474489397154405 Val Phi: 0.17914897661942703\n",
            "Epoch: 36 Train Amp: 0.004869395896215693 Train Phi: 0.1429380881736468 Val Amp: 0.005180396462002626 Val Phi: 0.17809156844249138\n",
            "Epoch: 37 Train Amp: 0.004853304354746721 Train Phi: 0.14152173510904592 Val Amp: 0.005180331090321908 Val Phi: 0.17840424753152406\n",
            "Epoch: 38 Train Amp: 0.004828108694778451 Train Phi: 0.14007190013280973 Val Amp: 0.005325939900313432 Val Phi: 0.17840911448001862\n",
            "Epoch: 39 Train Amp: 0.0048153422009121925 Train Phi: 0.1376801397511151 Val Amp: 0.005335363917625868 Val Phi: 0.17428915890363547\n",
            "Epoch: 40 Train Amp: 0.0047689642110317326 Train Phi: 0.13536668777715213 Val Amp: 0.005132234368759852 Val Phi: 0.1740820763202814\n",
            "Epoch: 41 Train Amp: 0.004758044469431354 Train Phi: 0.13595625256270044 Val Amp: 0.005094523684909711 Val Phi: 0.17112025274680212\n",
            "Epoch: 42 Train Amp: 0.004767254476189987 Train Phi: 0.13425624401748928 Val Amp: 0.005208605685486243 Val Phi: 0.17156871007038996\n",
            "Epoch: 43 Train Amp: 0.004693732480031427 Train Phi: 0.13278757188484758 Val Amp: 0.005041360389441252 Val Phi: 0.17193958392510048\n",
            "Epoch: 44 Train Amp: 0.0046967498112516675 Train Phi: 0.1322314795652194 Val Amp: 0.005238693207502365 Val Phi: 0.17215552811439222\n",
            "Epoch: 45 Train Amp: 0.00469021239049078 Train Phi: 0.1310294289531568 Val Amp: 0.005088560892125735 Val Phi: 0.170609162403987\n",
            "Epoch: 46 Train Amp: 0.00466480967491304 Train Phi: 0.13091404234140985 Val Amp: 0.0052097707342069885 Val Phi: 0.17060982951751122\n",
            "Epoch: 47 Train Amp: 0.004655248553698656 Train Phi: 0.13052667798981007 Val Amp: 0.005058213208730404 Val Phi: 0.1668035605779061\n",
            "Epoch: 48 Train Amp: 0.004625478009284166 Train Phi: 0.12816891092884988 Val Amp: 0.005030221735628752 Val Phi: 0.1675251298225843\n",
            "Epoch: 49 Train Amp: 0.004603760934602391 Train Phi: 0.1284044341936271 Val Amp: 0.005205826117442205 Val Phi: 0.16643349482462957\n",
            "Epoch: 50 Train Amp: 0.004595162023529099 Train Phi: 0.12543712275796357 Val Amp: 0.005107783425885897 Val Phi: 0.16484874486923218\n"
          ]
        }
      ]
    }
  ]
}